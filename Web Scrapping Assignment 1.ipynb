{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30dea8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd1d576",
   "metadata": {},
   "source": [
    "# Q1. Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9834b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Header Tags\n",
       "0           Welcome to Wikipedia\n",
       "1  From today's featured article\n",
       "2               Did you know ...\n",
       "3                    In the news\n",
       "4                    On this day\n",
       "5       Today's featured picture\n",
       "6       Other areas of Wikipedia\n",
       "7    Wikipedia's sister projects\n",
       "8            Wikipedia languages"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup=BeautifulSoup(page.content)\n",
    "header=[]\n",
    "for i in soup.find_all('span',class_=\"mw-headline\"):\n",
    "    header.append(i.text)\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Header Tags':header})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8ea5a",
   "metadata": {},
   "source": [
    "# Q2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82f945f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB’s Top rated 100 movies’ data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>9</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>9</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>9</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Yankee Doodle Dandy</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>American Graffiti</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Terms of Endearment</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>An American in Paris</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Name Rating Year of Release\n",
       "1                         The Shawshank Redemption    9.3            1994\n",
       "2                                    The Godfather    9.2            1972\n",
       "3    The Lord of the Rings: The Return of the King      9            2003\n",
       "4                            The Godfather Part II      9            1974\n",
       "5                                 Schindler's List      9            1993\n",
       "..                                             ...    ...             ...\n",
       "96                             Yankee Doodle Dandy    7.6            1942\n",
       "97                               Wuthering Heights    7.5            1939\n",
       "98                               American Graffiti    7.4            1973\n",
       "99                             Terms of Endearment    7.4            1983\n",
       "100                           An American in Paris    7.2            1951\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_movies=requests.get('https://www.imdb.com/list/ls055592025/?sort=user_rating,desc&st_dt=&mode=detail&page=1')\n",
    "soup=BeautifulSoup(imdb_movies.content)\n",
    "data=soup.find_all('h3',class_=\"lister-item-header\")\n",
    "movies_name=[]\n",
    "for i in data:\n",
    "    for j in i.find_all('a'):\n",
    "        movies_name.append(j.text)\n",
    "rating=[]\n",
    "for j in soup.find_all('div',class_=\"ipl-rating-star small\"):\n",
    "    rating.append(j.text.replace('\\n',''))\n",
    "yor=[]\n",
    "for k in soup.find_all('span',class_=\"lister-item-year text-muted unbold\"):\n",
    "    yor.append(k.text.replace('(','').replace(')',''))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.DataFrame({'Name':movies_name,'Rating':rating,'Year of Release':yor})\n",
    "print(\"IMDB’s Top rated 100 movies’ data\")\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c7393",
   "metadata": {},
   "source": [
    "# Q3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc75b300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB’s Top rated 100 Indian movies’ data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>9</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>9</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>9</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Yankee Doodle Dandy</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>American Graffiti</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Terms of Endearment</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>An American in Paris</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Name Rating Year of Release\n",
       "1                         The Shawshank Redemption    9.3            1994\n",
       "2                                    The Godfather    9.2            1972\n",
       "3    The Lord of the Rings: The Return of the King      9            2003\n",
       "4                            The Godfather Part II      9            1974\n",
       "5                                 Schindler's List      9            1993\n",
       "..                                             ...    ...             ...\n",
       "96                             Yankee Doodle Dandy    7.6            1942\n",
       "97                               Wuthering Heights    7.5            1939\n",
       "98                               American Graffiti    7.4            1973\n",
       "99                             Terms of Endearment    7.4            1983\n",
       "100                           An American in Paris    7.2            1951\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_movies=requests.get('https://www.imdb.com/list/ls009997493/?sort=user_rating,desc&st_dt=&mode=detail&page=1')\n",
    "soup=BeautifulSoup(ind_movies.content)\n",
    "d1=soup.find_all('td',class_=\"titleColumn\")\n",
    "movies_name=[]\n",
    "for i in d1:\n",
    "    for j in i.find_all('a'):\n",
    "        movies_name.append(j.text)\n",
    "rating=[]\n",
    "for j in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    rating.append(j.text.replace('\\n',''))\n",
    "yor=[]\n",
    "for k in soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "    yor.append(k.text.replace('(','').replace(')',''))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data=pd.DataFrame({'Name':movies_name,'Rating':rating,'Year of Release':yor})\n",
    "print(\"IMDB’s Top rated 100 Indian movies’ data\")\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c19806d",
   "metadata": {},
   "source": [
    "# Q4. Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0564d51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Shri Ram Nath Kovind (birth - 1945)</th>\n",
       "      <td>Term of Office: 25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shri Pranab Mukherjee (1935-2020)</th>\n",
       "      <td>Term of Office: 25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smt Pratibha Devisingh Patil (birth - 1934)</th>\n",
       "      <td>Term of Office: 25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DR. A.P.J. Abdul Kalam (1931-2015)</th>\n",
       "      <td>Term of Office: 25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shri K. R. Narayanan (1920 - 2005)</th>\n",
       "      <td>Term of Office: 25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr Shankar Dayal Sharma (1918-1999)</th>\n",
       "      <td>Term of Office: 25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shri R Venkataraman (1910-2009)</th>\n",
       "      <td>Term of Office: 25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Giani Zail Singh (1916-1994)</th>\n",
       "      <td>Term of Office: 25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shri Neelam Sanjiva Reddy (1913-1996)</th>\n",
       "      <td>Term of Office: 25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Fakhruddin Ali Ahmed (1905-1977)</th>\n",
       "      <td>Term of Office: 24 August, 1974 to 11 February...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shri Varahagiri Venkata Giri (1894-1980)</th>\n",
       "      <td>Term of Office: 3 May, 1969 to 20 July, 1969 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Zakir Husain (1897-1969)</th>\n",
       "      <td>Term of Office: 13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Sarvepalli Radhakrishnan (1888-1975)</th>\n",
       "      <td>Term of Office: 13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr. Rajendra Prasad (1884-1963)</th>\n",
       "      <td>Term of Office: 26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                Term of Office\n",
       "Name                                                                                          \n",
       "Shri Ram Nath Kovind (birth - 1945)            Term of Office: 25 July, 2017 to 25 July, 2022 \n",
       "Shri Pranab Mukherjee (1935-2020)              Term of Office: 25 July, 2012 to 25 July, 2017 \n",
       "Smt Pratibha Devisingh Patil (birth - 1934)    Term of Office: 25 July, 2007 to 25 July, 2012 \n",
       "DR. A.P.J. Abdul Kalam (1931-2015)             Term of Office: 25 July, 2002 to 25 July, 2007 \n",
       "Shri K. R. Narayanan (1920 - 2005)             Term of Office: 25 July, 1997 to 25 July, 2002 \n",
       "Dr Shankar Dayal Sharma (1918-1999)            Term of Office: 25 July, 1992 to 25 July, 1997 \n",
       "Shri R Venkataraman (1910-2009)                Term of Office: 25 July, 1987 to 25 July, 1992 \n",
       "Giani Zail Singh (1916-1994)                   Term of Office: 25 July, 1982 to 25 July, 1987 \n",
       "Shri Neelam Sanjiva Reddy (1913-1996)          Term of Office: 25 July, 1977 to 25 July, 1982 \n",
       "Dr. Fakhruddin Ali Ahmed (1905-1977)         Term of Office: 24 August, 1974 to 11 February...\n",
       "Shri Varahagiri Venkata Giri (1894-1980)     Term of Office: 3 May, 1969 to 20 July, 1969 a...\n",
       "Dr. Zakir Husain (1897-1969)                       Term of Office: 13 May, 1967 to 3 May, 1969\n",
       "Dr. Sarvepalli Radhakrishnan (1888-1975)          Term of Office: 13 May, 1962 to 13 May, 1967\n",
       "Dr. Rajendra Prasad (1884-1963)               Term of Office: 26 January, 1950 to 13 May, 1962"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indian_president=requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "soup=BeautifulSoup(indian_president.content)\n",
    "pres=soup.find_all('div',class_=\"presidentListing\")\n",
    "name=[]\n",
    "for i in pres:\n",
    "    for j in i.find_all('h3'):\n",
    "        name.append(j.text.replace('\\n',''))\n",
    "term=[]\n",
    "for a in pres:\n",
    "    for b in a.find_all('p'):\n",
    "        term.append(b.text)\n",
    "del term[1:9:2]\n",
    "import pandas as pd\n",
    "df= pd.DataFrame({'Name':name, 'Term of Office':term})\n",
    "df1=df.set_index('Name')\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cda410",
   "metadata": {},
   "source": [
    "# Q5. Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2589ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams in men’s cricket :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>26</td>\n",
       "      <td>3,045</td>\n",
       "      <td>117               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>30</td>\n",
       "      <td>3,400</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>32</td>\n",
       "      <td>3,572</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>41</td>\n",
       "      <td>4,515</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>25</td>\n",
       "      <td>2,649</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,392</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>33</td>\n",
       "      <td>3,129</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>34</td>\n",
       "      <td>2,976</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>20</td>\n",
       "      <td>1,419</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Matches Points  \\\n",
       "1    New Zealand      26  3,045   \n",
       "2        England      30  3,400   \n",
       "3      Australia      32  3,572   \n",
       "4          India      41  4,515   \n",
       "5       Pakistan      25  2,649   \n",
       "6   South Africa      24  2,392   \n",
       "7     Bangladesh      33  3,129   \n",
       "8      Sri Lanka      34  2,976   \n",
       "9    Afghanistan      20  1,419   \n",
       "10   West Indies      41  2,902   \n",
       "\n",
       "                                               Rating  \n",
       "1                               117               ...  \n",
       "2                                                 113  \n",
       "3                                                 112  \n",
       "4                                                 110  \n",
       "5                                                 106  \n",
       "6                                                 100  \n",
       "7                                                  95  \n",
       "8                                                  88  \n",
       "9                                                  71  \n",
       "10                                                 71  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cricket=requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup=BeautifulSoup(cricket.content)\n",
    "team=[]\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    team.append(i.text)\n",
    "m1=[]\n",
    "for j in soup.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    m1.append(j.text)\n",
    "m2=[]\n",
    "for k in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    m2.append(k.text)\n",
    "del m2[1:39:2]\n",
    "matches=m1+m2\n",
    "p1=[]\n",
    "for l in soup.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    p1.append(l.text)\n",
    "p2=[]\n",
    "for m in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    p2.append(m.text)\n",
    "del p2[0:39:2]\n",
    "points=p1+p2\n",
    "r1=[]\n",
    "for n in soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    r1.append(n.text.replace('\\n',''))\n",
    "r2=[]\n",
    "for o in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    r2.append(o.text)\n",
    "rating=r1+r2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.DataFrame({'Team':team,'Matches':matches,'Points':points,'Rating':rating})\n",
    "print('Top 10 ODI teams in men’s cricket :')\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39daa9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Batsmen :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsmen</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Batsmen                     Team Rating\n",
       "1              Babar Azam  PAK                        891\n",
       "2   Rassie van der Dussen                       SA    766\n",
       "3             Imam-ul-Haq                      PAK    764\n",
       "4         Quinton de Kock                       SA    759\n",
       "5            David Warner                      AUS    747\n",
       "6             Virat Kohli                      IND    726\n",
       "7             Steve Smith                      AUS    719\n",
       "8            Rohit Sharma                      IND    715\n",
       "9          Jonny Bairstow                      ENG    710\n",
       "10           Fakhar Zaman                      PAK    695"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batsmen=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "soup=BeautifulSoup(batsmen.content)\n",
    "p1=[]\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    p1.append(i.text)\n",
    "p2=[]\n",
    "for j in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    p2.append(j.text.replace('\\n',''))\n",
    "player=p1+p2\n",
    "t1=[]\n",
    "for a in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    t1.append(a.text.replace('\\n',''))\n",
    "t2=[]\n",
    "for b in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    t2.append(b.text)\n",
    "team=t1+t2\n",
    "r1=[]\n",
    "for n in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    r1.append(n.text)\n",
    "r2=[]\n",
    "for o in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    r2.append(o.text)\n",
    "rating=r1+r2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.DataFrame({'Batsmen':player,'Team':team,'Rating':rating})\n",
    "print('Top 10 ODI Batsmen :')\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8121fb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Bowlers :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowlers</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Bowlers                    Team Rating\n",
       "1         Trent Boult  NZ                        744\n",
       "2      Josh Hazlewood                     AUS    727\n",
       "3      Mitchell Starc                     AUS    665\n",
       "4         Rashid Khan                     AFG    659\n",
       "5          Matt Henry                      NZ    656\n",
       "6          Adam Zampa                     AUS    655\n",
       "7      Shaheen Afridi                     PAK    654\n",
       "8     Shakib Al Hasan                     BAN    652\n",
       "9   Mustafizur Rahman                     BAN    638\n",
       "10   Mujeeb Ur Rahman                     AFG    637"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowlers=requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "soup=BeautifulSoup(bowlers.content)\n",
    "p1=[]\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    p1.append(i.text)\n",
    "p2=[]\n",
    "for j in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    p2.append(j.text.replace('\\n',''))\n",
    "player=p1+p2\n",
    "t1=[]\n",
    "for a in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    t1.append(a.text.replace('\\n',''))\n",
    "t2=[]\n",
    "for b in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    t2.append(b.text)\n",
    "team=t1+t2\n",
    "r1=[]\n",
    "for n in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    r1.append(n.text)\n",
    "r2=[]\n",
    "for o in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    r2.append(o.text)\n",
    "rating=r1+r2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.DataFrame({'Bowlers':player,'Team':team,'Rating':rating})\n",
    "print('Top 10 ODI Bowlers :')\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c817b4b",
   "metadata": {},
   "source": [
    "# Q6. Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5246f84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams in Women’s cricket :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>3,061</td>\n",
       "      <td>170               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>28</td>\n",
       "      <td>3,342</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>25</td>\n",
       "      <td>2,553</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,535</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>13</td>\n",
       "      <td>983</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thailand</td>\n",
       "      <td>8</td>\n",
       "      <td>572</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>1,519</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Matches Points  \\\n",
       "1      Australia      18  3,061   \n",
       "2        England      28  3,342   \n",
       "3   South Africa      26  3,098   \n",
       "4          India      27  2,820   \n",
       "5    New Zealand      25  2,553   \n",
       "6    West Indies      27  2,535   \n",
       "7     Bangladesh      13    983   \n",
       "8       Thailand       8    572   \n",
       "9       Pakistan      24  1,519   \n",
       "10     Sri Lanka       8    353   \n",
       "\n",
       "                                               Rating  \n",
       "1                               170               ...  \n",
       "2                                                 119  \n",
       "3                                                 119  \n",
       "4                                                 104  \n",
       "5                                                 102  \n",
       "6                                                  94  \n",
       "7                                                  76  \n",
       "8                                                  72  \n",
       "9                                                  63  \n",
       "10                                                 44  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women_cricket=requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup=BeautifulSoup(women_cricket.content)\n",
    "team=[]\n",
    "for i in soup.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    team.append(i.text)\n",
    "m1=[]\n",
    "for j in soup.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    m1.append(j.text)\n",
    "m2=[]\n",
    "for k in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    m2.append(k.text)\n",
    "del m2[1:39:2]\n",
    "matches=m1+m2\n",
    "p1=[]\n",
    "for l in soup.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    p1.append(l.text)\n",
    "p2=[]\n",
    "for m in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    p2.append(m.text)\n",
    "del p2[0:39:2]\n",
    "points=p1+p2\n",
    "r1=[]\n",
    "for n in soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    r1.append(n.text.replace('\\n',''))\n",
    "r2=[]\n",
    "for o in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    r2.append(o.text)\n",
    "rating=r1+r2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.DataFrame({'Team':team,'Matches':matches,'Points':points,'Rating':rating})\n",
    "print('Top 10 ODI teams in Women’s cricket :')\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85fc3c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Womens ODI Battting Players :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batting Players</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Batting Players                     Team Rating\n",
       "1          Alyssa Healy  AUS                        785\n",
       "2           Beth Mooney                      AUS    749\n",
       "3       Laura Wolvaardt                       SA    732\n",
       "4        Natalie Sciver                      ENG    731\n",
       "5      Harmanpreet Kaur                      IND    716\n",
       "6       Smriti Mandhana                      IND    714\n",
       "7           Meg Lanning                      AUS    710\n",
       "8        Rachael Haynes                      AUS    701\n",
       "9   Chamari Athapaththu                       SL    655\n",
       "10         Ellyse Perry                      AUS    642"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women_batsmen=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "soup=BeautifulSoup(women_batsmen.content)\n",
    "p1=[]\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    p1.append(i.text)\n",
    "p2=[]\n",
    "for j in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    p2.append(j.text.replace('\\n',''))\n",
    "player=p1+p2\n",
    "t1=[]\n",
    "for a in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    t1.append(a.text.replace('\\n',''))\n",
    "t2=[]\n",
    "for b in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    t2.append(b.text)\n",
    "team=t1+t2\n",
    "r1=[]\n",
    "for n in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    r1.append(n.text)\n",
    "r2=[]\n",
    "for o in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    r2.append(o.text)\n",
    "rating=r1+r2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.DataFrame({'Batting Players':player,'Team':team,'Rating':rating})\n",
    "print('Top 10 Womens ODI Battting Players :')\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "254c0dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Womens ODI All-Rounder :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All-Rounder</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          All-Rounder                     Team Rating\n",
       "1        Ellyse Perry  AUS                        374\n",
       "2     Hayley Matthews                       WI    373\n",
       "3      Natalie Sciver                      ENG    371\n",
       "4      Marizanne Kapp                       SA    349\n",
       "5         Amelia Kerr                       NZ    336\n",
       "6       Deepti Sharma                      IND    322\n",
       "7    Ashleigh Gardner                      AUS    270\n",
       "8       Jess Jonassen                      AUS    246\n",
       "9      Jhulan Goswami                      IND    214\n",
       "10  Sophie Ecclestone                      ENG    205"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "women_allrounder=requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "soup=BeautifulSoup(women_allrounder.content)\n",
    "p1=[]\n",
    "for i in soup.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    p1.append(i.text)\n",
    "p2=[]\n",
    "for j in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    p2.append(j.text.replace('\\n',''))\n",
    "player=p1+p2\n",
    "t1=[]\n",
    "for a in soup.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    t1.append(a.text.replace('\\n',''))\n",
    "t2=[]\n",
    "for b in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    t2.append(b.text)\n",
    "team=t1+t2\n",
    "r1=[]\n",
    "for n in soup.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    r1.append(n.text)\n",
    "r2=[]\n",
    "for o in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    r2.append(o.text)\n",
    "rating=r1+r2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.DataFrame({'All-Rounder':player,'Team':team,'Rating':rating})\n",
    "print('Top 10 Womens ODI All-Rounder :')\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62c6e5",
   "metadata": {},
   "source": [
    "# Q7. rite a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "i) Headline\n",
    "\n",
    "ii) Time\n",
    "\n",
    "iii) News Link\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b59457f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Headline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Self-made millionaire: 3 habits to start in your 20s if you want to succeed</th>\n",
       "      <td>44 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/15/self-made-mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Want to sound more assertive? Ditch these 4 phrases that make you look 'weak or timid': Word experts</th>\n",
       "      <td>54 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/15/want-to-sound-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The most-popular big tech default email programs are old and vulnerable</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/15/the-most-popul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State-run auto-IRA programs continue growing as more options launch</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/15/state-run-auto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food fraud secretly infiltrates America. Here's how you can avoid it</th>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/15/food-fraud-sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 auto industry predictions for investors to keep an eye on this year</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/15/ten-auto-indus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark Cuban on the company that made him rich: ‘People thought I was an idiot’</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/15/mark-cuban-on-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wall Street's favorite retail stocks include Amazon, a little-known shoe company</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/15/wall-streets-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A busy movie calendar will lead to a 15% jump in box office sales, JPMorgan says</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/15/a-busier-movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>These tactical trades are among Goldman's favorite ways to play earnings season</th>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/15/these-tactical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>More classified documents found at Biden’s Delaware home, White House counsel says</th>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/white-house-sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The biggest risks of using Bluetooth trackers like Apple AirTag, Tile</th>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/the-biggest-se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Veganuary: 3 ways to meet your protein goals on a plant-based diet</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/veganuary-3-wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Investing in last year's top 10 stocks is 'a recipe for disaster,' expert says</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/best-performin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 side hustles for introverts: Some can bring in tens of thousands of dollars</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/side-hustles-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Here are the odds you'll win the $404 million Powerball jackpot</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/powerball-odds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The condo king of Miami is betting big on a new Fisher Island luxury project</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/condo-king-mia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carmakers upgrade lineups to meet high-end demand, scale back on less expensive cars</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/carmakers-upgr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What it’s like to deliver for Amazon in new electric Rivian vans</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/what-its-like-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The bold bullish case to be made for U.S. stocks</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/the-bold-bulli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Earnings stars: Stocks expected to post the biggest profit growth of 2023</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/earnings-stars...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morgan Stanley says these are the most undervalued stocks this year</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/stocks-like-di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stocks on a roll. But overbought market, earnings key hurdles in the week ahead</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/investing-club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The zero-fare public transit movement is picking up momentum</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/zero-fare-publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Building self-discipline by age 27 is crucial, says expert: 3 ways to do it</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/psychiatrist-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iran executes British-Iranian national despite UK, U.S. pleas</th>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/iran-executes-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rising commodities prices could be a tailwind for Caterpillar</th>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/rising-commodi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cramer's lightning round: Costamare is not a buy</th>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cramer’s week ahead: Wait before trading on company earnings</th>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/cramers-week-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDC review finds it’s unlikely Pfizer booster carries stroke risk for seniors</th>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/pfizer-covid-b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Time  \\\n",
       "Headline                                                               \n",
       "Self-made millionaire: 3 habits to start in you...        44 Min Ago   \n",
       "Want to sound more assertive? Ditch these 4 phr...        54 Min Ago   \n",
       "The most-popular big tech default email program...       2 Hours Ago   \n",
       "State-run auto-IRA programs continue growing as...       2 Hours Ago   \n",
       "Food fraud secretly infiltrates America. Here's...       2 Hours Ago   \n",
       "10 auto industry predictions for investors to k...       3 Hours Ago   \n",
       "Mark Cuban on the company that made him rich: ‘...       3 Hours Ago   \n",
       "Wall Street's favorite retail stocks include Am...       3 Hours Ago   \n",
       "A busy movie calendar will lead to a 15% jump i...       3 Hours Ago   \n",
       "These tactical trades are among Goldman's favor...       3 Hours Ago   \n",
       "More classified documents found at Biden’s Dela...      23 Hours Ago   \n",
       "The biggest risks of using Bluetooth trackers l...      23 Hours Ago   \n",
       "Veganuary: 3 ways to meet your protein goals on...  January 14, 2023   \n",
       "Investing in last year's top 10 stocks is 'a re...  January 14, 2023   \n",
       "4 side hustles for introverts: Some can bring i...  January 14, 2023   \n",
       "Here are the odds you'll win the $404 million P...  January 14, 2023   \n",
       "The condo king of Miami is betting big on a new...  January 14, 2023   \n",
       "Carmakers upgrade lineups to meet high-end dema...  January 14, 2023   \n",
       "What it’s like to deliver for Amazon in new ele...  January 14, 2023   \n",
       "The bold bullish case to be made for U.S. stocks    January 14, 2023   \n",
       "Earnings stars: Stocks expected to post the big...  January 14, 2023   \n",
       "Morgan Stanley says these are the most underval...  January 14, 2023   \n",
       "Stocks on a roll. But overbought market, earnin...  January 14, 2023   \n",
       "The zero-fare public transit movement is pickin...  January 14, 2023   \n",
       "Building self-discipline by age 27 is crucial, ...  January 14, 2023   \n",
       "Iran executes British-Iranian national despite ...  January 14, 2023   \n",
       "Rising commodities prices could be a tailwind f...  January 13, 2023   \n",
       "Cramer's lightning round: Costamare is not a buy    January 13, 2023   \n",
       "Cramer’s week ahead: Wait before trading on com...  January 13, 2023   \n",
       "CDC review finds it’s unlikely Pfizer booster c...  January 13, 2023   \n",
       "\n",
       "                                                                                            News Link  \n",
       "Headline                                                                                               \n",
       "Self-made millionaire: 3 habits to start in you...  https://www.cnbc.com/2023/01/15/self-made-mill...  \n",
       "Want to sound more assertive? Ditch these 4 phr...  https://www.cnbc.com/2023/01/15/want-to-sound-...  \n",
       "The most-popular big tech default email program...  https://www.cnbc.com/2023/01/15/the-most-popul...  \n",
       "State-run auto-IRA programs continue growing as...  https://www.cnbc.com/2023/01/15/state-run-auto...  \n",
       "Food fraud secretly infiltrates America. Here's...  https://www.cnbc.com/2023/01/15/food-fraud-sec...  \n",
       "10 auto industry predictions for investors to k...  https://www.cnbc.com/2023/01/15/ten-auto-indus...  \n",
       "Mark Cuban on the company that made him rich: ‘...  https://www.cnbc.com/2023/01/15/mark-cuban-on-...  \n",
       "Wall Street's favorite retail stocks include Am...  https://www.cnbc.com/2023/01/15/wall-streets-f...  \n",
       "A busy movie calendar will lead to a 15% jump i...  https://www.cnbc.com/2023/01/15/a-busier-movie...  \n",
       "These tactical trades are among Goldman's favor...  https://www.cnbc.com/2023/01/15/these-tactical...  \n",
       "More classified documents found at Biden’s Dela...  https://www.cnbc.com/2023/01/14/white-house-sa...  \n",
       "The biggest risks of using Bluetooth trackers l...  https://www.cnbc.com/2023/01/14/the-biggest-se...  \n",
       "Veganuary: 3 ways to meet your protein goals on...  https://www.cnbc.com/2023/01/14/veganuary-3-wa...  \n",
       "Investing in last year's top 10 stocks is 'a re...  https://www.cnbc.com/2023/01/14/best-performin...  \n",
       "4 side hustles for introverts: Some can bring i...  https://www.cnbc.com/2023/01/14/side-hustles-f...  \n",
       "Here are the odds you'll win the $404 million P...  https://www.cnbc.com/2023/01/14/powerball-odds...  \n",
       "The condo king of Miami is betting big on a new...  https://www.cnbc.com/2023/01/14/condo-king-mia...  \n",
       "Carmakers upgrade lineups to meet high-end dema...  https://www.cnbc.com/2023/01/14/carmakers-upgr...  \n",
       "What it’s like to deliver for Amazon in new ele...  https://www.cnbc.com/2023/01/14/what-its-like-...  \n",
       "The bold bullish case to be made for U.S. stocks    https://www.cnbc.com/2023/01/14/the-bold-bulli...  \n",
       "Earnings stars: Stocks expected to post the big...  https://www.cnbc.com/2023/01/14/earnings-stars...  \n",
       "Morgan Stanley says these are the most underval...  https://www.cnbc.com/2023/01/14/stocks-like-di...  \n",
       "Stocks on a roll. But overbought market, earnin...  https://www.cnbc.com/2023/01/14/investing-club...  \n",
       "The zero-fare public transit movement is pickin...  https://www.cnbc.com/2023/01/14/zero-fare-publ...  \n",
       "Building self-discipline by age 27 is crucial, ...  https://www.cnbc.com/2023/01/14/psychiatrist-f...  \n",
       "Iran executes British-Iranian national despite ...  https://www.cnbc.com/2023/01/14/iran-executes-...  \n",
       "Rising commodities prices could be a tailwind f...  https://www.cnbc.com/2023/01/13/rising-commodi...  \n",
       "Cramer's lightning round: Costamare is not a buy    https://www.cnbc.com/2023/01/13/cramers-lightn...  \n",
       "Cramer’s week ahead: Wait before trading on com...  https://www.cnbc.com/2023/01/13/cramers-week-a...  \n",
       "CDC review finds it’s unlikely Pfizer booster c...  https://www.cnbc.com/2023/01/13/pfizer-covid-b...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "soup=BeautifulSoup(news.content)\n",
    "headline = []\n",
    "for i in soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    headline.append(i.text)\n",
    "time = []\n",
    "for j in soup.find_all('time',class_=\"LatestNews-timestamp\"):\n",
    "    time.append(j.text)\n",
    "news_link = []\n",
    "for k in soup.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    news_link.append(k['href'])\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'Headline':headline, 'Time':time, 'News Link': news_link})\n",
    "df1=df.set_index('Headline')\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24784da",
   "metadata": {},
   "source": [
    "# Q8. Write a python program to scrape the details of most downloaded articles from AI in last 90 days. https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles Scrape below mentioned details :\n",
    "i) Paper Title\n",
    "\n",
    "ii) Authors\n",
    "\n",
    "iii) Published Date\n",
    "\n",
    "iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91113e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paper Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Authors, Published Date, Paper URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "soup=BeautifulSoup(page.content)\n",
    "title = []\n",
    "for i in soup.find_all('h2',class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    title.append(i.text)\n",
    "author = []\n",
    "for j in soup.find_all('span',class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    author.append(j.text)\n",
    "pub_date = []\n",
    "for k in soup.find_all('span',class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    pub_date.append(k.text)\n",
    "paper_url = []\n",
    "for l in soup.find_all('a',class_=\"sc-5smygv-0 nrDZj\"):\n",
    "    paper_url.append(l['href'])\n",
    "import pandas as pd\n",
    "df1=pd.DataFrame({'Paper Title':title, 'Authors':author, 'Published Date':pub_date, 'Paper URL':paper_url})\n",
    "df=df1.set_index('Paper Title')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2e482a",
   "metadata": {},
   "source": [
    "# Q9. Write a python program to scrape mentioned details from dineout.co.in :\n",
    "i) Restaurant name\n",
    "\n",
    "ii) Cuisine\n",
    "\n",
    "iii) Location\n",
    "\n",
    "iv) Ratings\n",
    "\n",
    "v) Image URL\n",
    "\n",
    "Answer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f47443e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Castle Barbeque</th>\n",
       "      <td>₹ 2,000 for 2 (approx) | Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jungle Jamboree</th>\n",
       "      <td>₹ 1,680 for 2 (approx) | North Indian, Asian, ...</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cafe Knosh</th>\n",
       "      <td>₹ 3,000 for 2 (approx) | Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Castle Barbeque</th>\n",
       "      <td>₹ 2,000 for 2 (approx) | Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Barbeque Company</th>\n",
       "      <td>₹ 1,700 for 2 (approx) | North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India Grill</th>\n",
       "      <td>₹ 2,400 for 2 (approx) | North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delhi Barbeque</th>\n",
       "      <td>₹ 1,800 for 2 (approx) | North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Monarch - Bar Be Que Village</th>\n",
       "      <td>₹ 1,900 for 2 (approx) | North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indian Grill Room</th>\n",
       "      <td>₹ 2,200 for 2 (approx) | North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Cuisine  \\\n",
       "Restaurant Name                                                                       \n",
       "Castle Barbeque                      ₹ 2,000 for 2 (approx) | Chinese, North Indian   \n",
       "Jungle Jamboree                   ₹ 1,680 for 2 (approx) | North Indian, Asian, ...   \n",
       "Cafe Knosh                            ₹ 3,000 for 2 (approx) | Italian, Continental   \n",
       "Castle Barbeque                      ₹ 2,000 for 2 (approx) | Chinese, North Indian   \n",
       "The Barbeque Company                 ₹ 1,700 for 2 (approx) | North Indian, Chinese   \n",
       "India Grill                          ₹ 2,400 for 2 (approx) | North Indian, Italian   \n",
       "Delhi Barbeque                                ₹ 1,800 for 2 (approx) | North Indian   \n",
       "The Monarch - Bar Be Que Village              ₹ 1,900 for 2 (approx) | North Indian   \n",
       "Indian Grill Room                    ₹ 2,200 for 2 (approx) | North Indian, Mughlai   \n",
       "\n",
       "                                                                           Location  \\\n",
       "Restaurant Name                                                                       \n",
       "Castle Barbeque                                      Connaught Place, Central Delhi   \n",
       "Jungle Jamboree                              3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "Cafe Knosh                        The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "Castle Barbeque                              Pacific Mall,Tagore Garden, West Delhi   \n",
       "The Barbeque Company                             Gardens Galleria,Sector 38A, Noida   \n",
       "India Grill                                    Hilton Garden Inn,Saket, South Delhi   \n",
       "Delhi Barbeque                       Taurus Sarovar Portico,Mahipalpur, South Delhi   \n",
       "The Monarch - Bar Be Que Village  Indirapuram Habitat Centre,Indirapuram, Ghaziabad   \n",
       "Indian Grill Room                  Suncity Business Tower,Golf Course Road, Gurgaon   \n",
       "\n",
       "                                 Ratings  \\\n",
       "Restaurant Name                            \n",
       "Castle Barbeque                      4.1   \n",
       "Jungle Jamboree                      3.9   \n",
       "Cafe Knosh                           4.3   \n",
       "Castle Barbeque                      3.9   \n",
       "The Barbeque Company                   4   \n",
       "India Grill                          3.9   \n",
       "Delhi Barbeque                       3.6   \n",
       "The Monarch - Bar Be Que Village     3.8   \n",
       "Indian Grill Room                    4.3   \n",
       "\n",
       "                                                                          Image URL  \n",
       "Restaurant Name                                                                      \n",
       "Castle Barbeque                   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "Jungle Jamboree                   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "Cafe Knosh                        https://im1.dineout.co.in/images/uploads/resta...  \n",
       "Castle Barbeque                   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "The Barbeque Company              https://im1.dineout.co.in/images/uploads/resta...  \n",
       "India Grill                       https://im1.dineout.co.in/images/uploads/resta...  \n",
       "Delhi Barbeque                    https://im1.dineout.co.in/images/uploads/resta...  \n",
       "The Monarch - Bar Be Que Village  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "Indian Grill Room                 https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dine = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "soup = BeautifulSoup(dine.content)\n",
    "rest_name = []\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    for j in i.find_all('a',class_=\"restnt-name ellipsis\"):\n",
    "        rest_name.append(j.text)\n",
    "cui = []\n",
    "for l in soup.find_all('div',class_=\"detail-info\"):\n",
    "    cui.append(l.text)\n",
    "loc = []\n",
    "for k in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    loc.append(k.text)\n",
    "rating = []\n",
    "for m in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    rating.append(m.text)\n",
    "image_url = []\n",
    "for n in soup.find_all('img',class_=\"no-img\"):\n",
    "    image_url.append(n['data-src'])\n",
    "import pandas\n",
    "df =pandas.DataFrame({'Restaurant Name':rest_name, 'Cuisine':cui, 'Location':loc, 'Ratings':rating, 'Image URL':image_url})\n",
    "df1=df.set_index('Restaurant Name')\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1eb4ba",
   "metadata": {},
   "source": [
    "# Q10. Write a python program to scrape the details of top publications from Google Scholar from https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "i) Rank\n",
    "\n",
    "ii) Publication\n",
    "\n",
    "iii) h5-index\n",
    "\n",
    "iv) h5-median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e39e0ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Publication, h5-index, h5-median]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "soup=BeautifulSoup(page.content)\n",
    "rank=[]\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text)\n",
    "pub=[]\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    pub.append(i.text)\n",
    "h5_index = []\n",
    "for k in soup.find_all('a',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5_index.append(k.text)\n",
    "h5m = []\n",
    "for l in soup.find_all('span',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5m.append(l.text)\n",
    "import pandas as pan\n",
    "df = pan.DataFrame({'Rank':rank, 'Publication':pub, 'h5-index':h5_index, 'h5-median':h5m})\n",
    "df1=df.set_index('Rank')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f37e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
